spring:
  # MyBatis (MyBatisProperties)
  datasource:
    url: jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf-8
    username: root
    password: 123456
    driver-class-name: com.mysql.jdbc.Driver

  # Redis (RedisProperties)
  redis:
    database: 0
    host: localhost
    port: 6379
    timeout: 0
    password:
    pool:
      max-active: 8
      max-wait: -1
      max-idle: 8
      min-idle: 0

  # kafka (KafkaProperties)
#  kafka:
#    # kafka服务器地址(可以多个英文逗号隔开)
#    bootstrap-servers: 192.168.255.129:9092,192.168.255.130:9092,192.168.255.131:9092
#    consumer:
#      # 指定一个默认的组名
#      group-id: test-consumer-group
#      enable-auto-commit: true
#      auto-commit-interval: 100
#      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
#      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
#      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
#      auto-offset-reset: earliest
#      # key/value的反序列化
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#    producer:
#      producer.retries: 0
#      # 批量抓取
#      batch-size: 65536
#      # 缓存容量
#      buffer-memory: 524288
#      # key/value的序列化
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer

    # elasticsearch (ElasticsearchProperties)
    data:
      elasticsearch:
        cluster-name: xmp-cluster
        cluster-nodes: localhost:9200

mybatis:
  type-aliases-package: com.example.module.domain
  config-locations: classpath:mybatis/mybatis-config.xml
  mapper-locations: classpath:mybatis/mapper/*.xml

# mapper
mapper:
    mappers:
        - com.example.module.plugin.BaseMapper
    not-empty: false
    identity: MYSQL
# pagehelper
pagehelper:
    helper-dialect: mysql
    reasonable: true
    support-methods-arguments: true
    params: count=countSql
